{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "[Load & Predict] from the saved model.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "k7ChPtavjszi",
        "7qCzFHuejyU7"
      ],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyPxpF6BIoxJBdhkCkJ5kN4D",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/setthawut8/ai/blob/main/%5BLoad_%26_Predict%5D_from_the_saved_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Build Functions for using these loaded model\n",
        "Inspirations as follows:\n",
        "- https://machinelearningmastery.com/save-load-keras-deep-learning-models/\n",
        "- https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/distribute/save_and_load.ipynb#scrollTo=jFcuzsI94bNA\n"
      ],
      "metadata": {
        "id": "ZSwTbZ7LDnvI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown --id :) #test_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wvmnwD9qlpzf",
        "outputId": "1bc90a55-d56e-4849-dae4-70cbe87735d8"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gdown/cli.py:131: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  category=FutureWarning,\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1Cq3FttnnzZa-RK7vlu94bJTRj8YD6vA5\n",
            "To: /content/test_translated banking data.csv\n",
            "100% 18.7M/18.7M [00:00<00:00, 245MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "test = pd.read_csv('/content/test_translated banking data.csv')"
      ],
      "metadata": {
        "id": "PxTdjWvJlq4R"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##TH2EN_CNN (2 functions)"
      ],
      "metadata": {
        "id": "k7ChPtavjszi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown --id 1XIUJkhLgjLxbei0QaA0RkPxTtNB6NZiG #model\n",
        "!gdown --id 1McFf6NPsxlL0g0XmXF9-J4yItudW2OIS #tokenizer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VLht-LtWP3ym",
        "outputId": "442e8489-3446-4602-f7b9-3f5d5aab5097"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gdown/cli.py:131: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  category=FutureWarning,\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1XIUJkhLgjLxbei0QaA0RkPxTtNB6NZiG\n",
            "To: /content/TH2EN_CNN.h5\n",
            "100% 154M/154M [00:00<00:00, 181MB/s]\n",
            "/usr/local/lib/python3.7/dist-packages/gdown/cli.py:131: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  category=FutureWarning,\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1McFf6NPsxlL0g0XmXF9-J4yItudW2OIS\n",
            "To: /content/tokenizer.pickle\n",
            "100% 460k/460k [00:00<00:00, 74.6MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample_test_x = test['translated'][:10]"
      ],
      "metadata": {
        "id": "ZM21-357RVHW"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "def text_to_vectors(pickle_path, docs, max_length_of_words):\n",
        "  with open(pickle_path, 'rb') as handle:\n",
        "    tokenizer = pickle.load(handle)\n",
        "  encoded_docs = tokenizer.texts_to_sequences(docs)\n",
        "  padded_docs = pad_sequences(encoded_docs, maxlen=max_length_of_words, padding='post')\n",
        "  vocab_size = len(tokenizer.word_index) + 1\n",
        "  return padded_docs, vocab_size"
      ],
      "metadata": {
        "id": "l_tclXh8UhCA"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "import numpy as np\n",
        "from keras.utils.np_utils import to_categorical\n",
        "\n",
        "X, vocab_size = text_to_vectors('/content/tokenizer.pickle', sample_test_x, 190)"
      ],
      "metadata": {
        "id": "uCW0Gjx3Op5J"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "def TH2EN_CNN_prediction(h5_path, padded_docs):\n",
        "  #Load the model: https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/keras/save_and_load.ipynb#scrollTo=SkGwf-50zLNn\n",
        "  # Recreate the exact same model, including its weights and the optimizer\n",
        "  new_model = tf.keras.models.load_model(h5_path)\n",
        "  # Show the model architecture\n",
        "  y_pred = new_model.predict(padded_docs)\n",
        "  rounded_labels_ypred = np.argmax(y_pred, axis=1)+1\n",
        "  return rounded_labels_ypred"
      ],
      "metadata": {
        "id": "Dvoyvy5EUlYt"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TH2EN_CNN_prediction('/content/TH2EN_CNN.h5', X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "obc1yBIBdlPe",
        "outputId": "1ed601a3-ffbc-4774-d298-a44b74da6abb"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f4ed01cdcb0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 8, 12,  7, 13,  8,  8,  7, 13,  7,  8])"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##TH2EN_GRU (2 functions)"
      ],
      "metadata": {
        "id": "7qCzFHuejyU7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown --id 1UNfJZq3ehiHO3MFnyYmI-o1_fLvoUnAx #model\n",
        "!gdown --id 1McFf6NPsxlL0g0XmXF9-J4yItudW2OIS #tokenizer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Z6nw98Fj2FQ",
        "outputId": "46b2222a-00bf-4839-ec71-86b03c2bf4f8"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gdown/cli.py:131: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  category=FutureWarning,\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1UNfJZq3ehiHO3MFnyYmI-o1_fLvoUnAx\n",
            "To: /content/TH2EN_GRU.h5\n",
            "100% 166M/166M [00:02<00:00, 59.9MB/s]\n",
            "/usr/local/lib/python3.7/dist-packages/gdown/cli.py:131: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  category=FutureWarning,\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1McFf6NPsxlL0g0XmXF9-J4yItudW2OIS\n",
            "To: /content/tokenizer.pickle\n",
            "100% 460k/460k [00:00<00:00, 127MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample_test_x = test['translated'][:10]"
      ],
      "metadata": {
        "id": "SI7qQRarmsCf"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "def text_to_vectors(pickle_path, docs, max_length_of_words):\n",
        "  with open(pickle_path, 'rb') as handle:\n",
        "    tokenizer = pickle.load(handle)\n",
        "  encoded_docs = tokenizer.texts_to_sequences(docs)\n",
        "  padded_docs = pad_sequences(encoded_docs, maxlen=max_length_of_words, padding='post')\n",
        "  vocab_size = len(tokenizer.word_index) + 1\n",
        "  return padded_docs, vocab_size"
      ],
      "metadata": {
        "id": "h7JOcDQ4onRW"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "import numpy as np\n",
        "from keras.utils.np_utils import to_categorical\n",
        "\n",
        "X, vocab_size = text_to_vectors('/content/tokenizer.pickle', sample_test_x, 190)"
      ],
      "metadata": {
        "id": "vGEj3E4VonRc"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "def TH2EN_GRU_prediction(h5_path, padded_docs):\n",
        "  #Load the model: https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/keras/save_and_load.ipynb#scrollTo=SkGwf-50zLNn\n",
        "  # Recreate the exact same model, including its weights and the optimizer\n",
        "  new_model = tf.keras.models.load_model(h5_path)\n",
        "  # Show the model architecture\n",
        "  y_pred = new_model.predict(padded_docs)\n",
        "  rounded_labels_ypred = np.argmax(y_pred, axis=1)+1\n",
        "  return rounded_labels_ypred"
      ],
      "metadata": {
        "id": "q-MRRoeMonRd"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TH2EN_GRU_prediction('/content/TH2EN_GRU.h5', X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0900d76a-86ab-4a1e-b79a-0a970ea166cd",
        "id": "pw2i5kdVonRd"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Layer gru will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer gru will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer gru will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f4e4432b560> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 8, 12,  7,  4,  8,  8,  7,  8,  7,  8])"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##TH2EN_CNN_and_GRU (1 Function)"
      ],
      "metadata": {
        "id": "RYrOGlPZo9vR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown --id 1XIUJkhLgjLxbei0QaA0RkPxTtNB6NZiG #model\n",
        "!gdown --id 1UNfJZq3ehiHO3MFnyYmI-o1_fLvoUnAx #model\n",
        "!gdown --id 1McFf6NPsxlL0g0XmXF9-J4yItudW2OIS #tokenizer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9fb3f37f-9dc6-416c-ce38-b5d60d16cea5",
        "id": "dIF8yZqbpCPf"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gdown/cli.py:131: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  category=FutureWarning,\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1XIUJkhLgjLxbei0QaA0RkPxTtNB6NZiG\n",
            "To: /content/TH2EN_CNN.h5\n",
            "100% 154M/154M [00:00<00:00, 343MB/s]\n",
            "/usr/local/lib/python3.7/dist-packages/gdown/cli.py:131: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  category=FutureWarning,\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1UNfJZq3ehiHO3MFnyYmI-o1_fLvoUnAx\n",
            "To: /content/TH2EN_GRU.h5\n",
            "100% 166M/166M [00:02<00:00, 64.9MB/s]\n",
            "/usr/local/lib/python3.7/dist-packages/gdown/cli.py:131: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  category=FutureWarning,\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1McFf6NPsxlL0g0XmXF9-J4yItudW2OIS\n",
            "To: /content/tokenizer.pickle\n",
            "100% 460k/460k [00:00<00:00, 123MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample_test_x = test['translated'][:10]"
      ],
      "metadata": {
        "id": "-9OTwREEpCPg"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "def text_to_vectors_and_prediction(pickle_path, docs, max_length_of_words, h5_path):\n",
        "  with open(pickle_path, 'rb') as handle:\n",
        "    tokenizer = pickle.load(handle)\n",
        "  encoded_docs = tokenizer.texts_to_sequences(docs)\n",
        "  padded_docs = pad_sequences(encoded_docs, maxlen=max_length_of_words, padding='post')\n",
        "  vocab_size = len(tokenizer.word_index) + 1\n",
        "\n",
        "  #Load the model: https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/keras/save_and_load.ipynb#scrollTo=SkGwf-50zLNn\n",
        "  # Recreate the exact same model, including its weights and the optimizer\n",
        "  new_model = tf.keras.models.load_model(h5_path)\n",
        "  # Show the model architecture\n",
        "  y_pred = new_model.predict(padded_docs)\n",
        "  rounded_labels_ypred = np.argmax(y_pred, axis=1)+1\n",
        "  return rounded_labels_ypred"
      ],
      "metadata": {
        "id": "G9G8Eq9lpAA1"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#CNN\n",
        "text_to_vectors_and_prediction('/content/tokenizer.pickle', sample_test_x, 190, '/content/TH2EN_CNN.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9xPmDvPZq87w",
        "outputId": "e543452a-1fc2-4ceb-b349-9904f8dbd765"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 8, 12,  7, 13,  8,  8,  7, 13,  7,  8])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#GRU\n",
        "text_to_vectors_and_prediction('/content/tokenizer.pickle', sample_test_x, 190, '/content/TH2EN_GRU.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vqPejzOWrHhF",
        "outputId": "6ef39146-8261-4bdf-8f86-90a7a8998fd0"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Layer gru will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer gru will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer gru will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 8, 12,  7,  4,  8,  8,  7,  8,  7,  8])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    }
  ]
}
